{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "knn_m2m.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQsEKH1mN3B4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSl0ZedCN-C3",
    "outputId": "bc1194c1-1212-4aea-9960-96423f03c634",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2121 596\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "path = '/content/drive/MyDrive/cs550/ml-latest-small'\n",
    "ratings = pd.read_csv(os.path.join(path, \"ratings.csv\"), sep=\",\", nrows=None)\n",
    "tags = pd.read_csv(os.path.join(path, \"tags.csv\"), sep=\",\", nrows=None)\n",
    "movies = pd.read_csv(os.path.join(path, \"movies.csv\"), sep=\",\", nrows=None)\n",
    "\n",
    "# final_dataset = ratings.pivot(index='movieId',columns='userId',values='rating')\n",
    "# final_dataset.fillna(0,inplace=True)\n",
    "# no_user_voted = ratings.groupby('movieId')['rating'].agg('count')\n",
    "# no_movies_voted = ratings.groupby('userId')['rating'].agg('count')\n",
    "\n",
    "# final_dataset = final_dataset.loc[no_user_voted[no_user_voted > 10].index,:]\n",
    "# final_dataset = final_dataset.loc[:,no_movies_voted[no_movies_voted > 50].index]\n",
    "# final_dataset.head()\n",
    "\n",
    "movie_count = ratings['movieId'].value_counts().reset_index().rename(columns={'index':'movieId', 'movieId': 'count'})\n",
    "user_count = ratings['userId'].value_counts().reset_index().rename(columns={'index':'userId', 'userId': 'count'})\n",
    "movie_count.head()\n",
    "user_count.head()\n",
    "userSet = set(user_count[user_count['count'] > 20]['userId'])\n",
    "movieSet = set(movie_count[movie_count['count'] > 10]['movieId'])\n",
    "print(len(movieSet), len(userSet))"
   ],
   "metadata": {
    "id": "lSNDBytEN-FP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "pattern = '\\(\\d\\d\\d\\d\\)'\n",
    "\n",
    "movie_title = movies['title']\n",
    "\n",
    "# title = movie_title.map(lambda x: re.sub(pattern, \" \", x))\n",
    "# year = movie_title.map(lambda x: re.findall(\"\\d\\d\\d\\d\", x)[-1] if re.search(\"\\d\\d\\d\\d\", x) is not None else \"0000\")\n",
    "# print(year)\n",
    "movie_year = {}\n",
    "movie_dict = {}\n",
    "movieIdset = set(movies[\"movieId\"])\n",
    "for movieId in movieIdset:\n",
    "  sub_tags = tags[tags['movieId']==movieId]\n",
    "  sub_movies = movies[movies['movieId']==movieId]\n",
    "  if movieId not in movie_dict:\n",
    "    movie_dict[movieId] = {}\n",
    "  title = sub_movies['title'].item()\n",
    "  movie_dict[movieId]['title'] = re.sub(pattern, \" \", title)\n",
    "  movie_dict[movieId]['genres'] = list(sub_movies['genres'])[0].replace(\"|\", \" \")\n",
    "  if len(sub_tags) > 0:\n",
    "    if \"tag\" not in movie_dict[movieId]:\n",
    "      movie_dict[movieId]['tag'] = \"\"\n",
    "    movie_dict[movieId]['tag'] += \" \".join(list(sub_tags['tag']))\n",
    "  movie_year[movieId] = int(re.findall(\"\\d\\d\\d\\d\", title)[-1]) if re.search(\"\\d\\d\\d\\d\", title) is not None else 1800\n",
    "# print(movie_dict)\n",
    "# print(movie_year)\n",
    "movie_text = {}\n",
    "for movieId, info in movie_dict.items():\n",
    "  movie_text[movieId] = info['title'].strip() + \" \" + info['genres'].strip() + ((\" tags \"+\" \".join(set(info['tag'].strip().split(\" \")))) if 'tag' in info else \"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhFgEFH_wql1",
    "outputId": "fa64c659-770a-4564-8d96-4648f9c64b4b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "378\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ratings_dataset = ratings.pivot(index='movieId',columns='userId',values='rating')\n",
    "ratings_dataset.fillna(0,inplace=True)\n",
    "# ratings_dataset = ratings_dataset.reset_index()\n",
    "no_user_voted = ratings.groupby('movieId')['rating'].agg('count')\n",
    "no_movies_voted = ratings.groupby('userId')['rating'].agg('count')\n",
    "final_dataset = ratings_dataset.loc[no_user_voted[no_user_voted > 10].index,:]\n",
    "final_dataset = final_dataset.loc[:,no_movies_voted[no_movies_voted > 50].index]\n",
    "final_dataset = final_dataset.reset_index()\n",
    "# final_dataset.shape\n",
    "movie_user_dict = final_dataset.set_index('movieId').T.to_dict('list')\n",
    "print(len(movie_user_dict[1]))"
   ],
   "metadata": {
    "id": "e5-6DkJOU2Ls",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMoQsFNbN-Hf",
    "outputId": "147d6137-6683-4aa6-864f-46b7122a3ddd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertModel, AdamW, BertConfig, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "movie_token = {}\n",
    "for movieId, text in movie_dict.items():\n",
    "  movie_token[movieId] = {}\n",
    "  encoded_dict = tokenizer.encode_plus(\n",
    "    text=movie_text[movieId],                      # Sentence to encode.\n",
    "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length = 210,           # Pad & truncate all sentences.\n",
    "    pad_to_max_length = True,\n",
    "    return_attention_mask = True,   # Construct attn. masks\n",
    "    return_tensors = 'pt',     # Return pytorch tensors.\n",
    "  )\n",
    "  movie_token[movieId]['input_ids'] = encoded_dict['input_ids']\n",
    "  movie_token[movieId]['attention_mask'] = encoded_dict['attention_mask']"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcmXuzhFN-Ju",
    "outputId": "61f797d6-dfe4-4078-943c-ec625004675b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "movie_vec = {}\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "for movieId in movieSet:\n",
    "  tokens = movie_token[movieId]\n",
    "  CLS = model(tokens['input_ids'], token_type_ids=None, attention_mask=tokens['attention_mask'])[1]\n",
    "  movie_vec[movieId] = CLS.detach().numpy().reshape(-1)\n",
    "  # print(movie_vec[movieId].shape)"
   ],
   "metadata": {
    "id": "k_UKtbOkN-N-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# with open(os.path.join(path, \"movie_vec.pkl\"), 'wb') as f:\n",
    "#   pkl.dump(movie_vec, f)"
   ],
   "metadata": {
    "id": "0UbWv0SU0NZi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(os.path.join(path, \"movie_vec.pkl\"), 'rb') as f:\n",
    "  movie_vec = pkl.load(f)\n",
    "# for movieId in movie_vec:\n",
    "#   movie_vec[movieId] = np.append(CLS.detach().numpy().reshape(-1), np.array(movie_user_dict[movieId]))\n",
    "# print(len(movie_vec))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NLFmWKxN-Qe",
    "outputId": "a01d9f5d-c089-4400-a062-cec27055b642",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2121, 769)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.DataFrame.from_dict(movie_vec, orient='index')\n",
    "csr_data = csr_matrix(data.values)\n",
    "# data = data.reset_index(inplace=True)\n",
    "data = data.reset_index().rename(columns={'index':'movieId'})\n",
    "data.shape\n",
    "# data.index"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgAlo5X1N-St",
    "outputId": "bbe037ea-a964-413a-efbe-c1b3418d11dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=15)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=15, n_jobs=-1)\n",
    "knn.fit(csr_data)"
   ],
   "metadata": {
    "id": "DKllCdlKN-U9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_movie_recommendation(movie_name, num_rec):\n",
    "    n_movies_to_reccomend = num_rec\n",
    "    movie_list = movies[movies['title'].str.contains(movie_name)]  \n",
    "    if len(movie_list):        \n",
    "        movieIdx= movie_list.iloc[0]['movieId']\n",
    "        # print(movieIdx)\n",
    "        vec = movie_vec[movieIdx]\n",
    "        movie_idx = data[data['movieId'] == movieIdx].index[0]\n",
    "        # print(movie_idx)\n",
    "        distances , indices = knn.kneighbors(csr_data[movie_idx],n_neighbors=n_movies_to_reccomend+1)    \n",
    "        rec_movie_indices = sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),key=lambda x: x[1])[:0:-1]\n",
    "        recommend_frame = []\n",
    "        for val in rec_movie_indices:\n",
    "            movie_idx = data.iloc[val[0]]['movieId']\n",
    "            idx = movies[movies['movieId'] == movie_idx].index\n",
    "            recommend_frame.append({'Title':movies.iloc[idx]['title'].values[0],'Distance':val[1]})\n",
    "        df = pd.DataFrame(recommend_frame,index=range(1,n_movies_to_reccomend+1))\n",
    "        return df\n",
    "    else:\n",
    "        return \"No movies found. Please check your input\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "0knP9ynilCVV",
    "outputId": "a551b58a-23b4-410d-c2c5-39cae3656b8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'No movies found. Please check your input'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "get_movie_recommendation(\"AvengersUltimate  (2006)\", 20)"
   ],
   "metadata": {
    "id": "5IH4ta-HlCXj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "mbK5NSXBlCZ0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "8i4-c7BalCb6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}